---
title: "Forecast Linear Augmented Projection (FLAP): A free lunch to reduce forecast error variance"
author: [
  "Yangzhuoran Fin Yang",
  "George Athanasopoulos",
  "Rob J Hyndman",
  "Anastasios Panagiotelis"
  ]
template: template.tex
keep-tex: true
bibliography:
  - ../references-key.bib
  - ../references-pkg.bib
format: 
  beamer: 
    pdf-engine: pdflatex
    biblio-title: "References"
    theme: monash
    fonttheme: monash
    colortheme: monashwhite
header-includes:
  - \usepackage{bm}
  - \usepackage{amsfonts}
  - \usepackage{tikz}
  - \usepackage[makeroom]{cancel}
  - \widowpenalties 1 150
  - \def\Var{\operatorname{Var}}
  - \def\E{\operatorname{E}}
  - \def\tr{\operatorname{tr}}
titlefontsize: 18
knitr:
   opts_chunk: 
     out-width: 100%
     out-height: 100%
execute: 
  eval: true
  cache: true
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| cache: false
knitr::read_chunk("flap-slides.R")
```
```{r library}
#| cache: false
```
```{r data}
```


## Forecast Linear Augmented Projection (FLAP)

A model-independent post-forecast adjustment method that can reduce forecast error variance.

- Averaging indirect forecasts from linear combinations (components)
- Projecting forecasts of augmented series
- Free lunch: no additional data or information needed

## What to expect

* Intuition with data

* Literature

* Method formulation

* Properties

* Empirical applications and simulation


## Australian tourism data

* The data include tourism information on seven states and territories which can be divided into 77 regions
  - For example, Melbourne, Sydney, East Coast

### Visitor nights
The total number of nights spent by Australians away from home recorded monthly

## Melbourne and Sydney

```{r p_syd_mel}
```

## Total and Region

```{r p_aus_mel}
```


## Intuition
\begin{block}{Observation}

1. Similar patterns are shared by different series.
2. Better signal-noise ratio in the linear combination.

\end{block}

\pause

\begin{alertblock}{One step further}
Finding components that 


1. are easy to forecast;

2. can capture the common signals;

3. can improve forecast of original series.
\end{alertblock}

## Literature

### Forecast reconciliation

* @WicEtAl2019: Projecting forecasts to be consistent with the hierarchical structure

### Forecast combination

* Combining forecasts of the target series
* @HolEtAl2021: Combining direct and indirect forecasts
* @PetSpi2021: Combining forecasts of selections and transformations of the target series ("wisdom of data")

## Literature

### Bagging

* @BerEtAl2016: Bagging ETS models to forecast
* @PetEtAl2018: The benefits of bagging originate from the model uncertainty

### Dynamic factor model (DFM)

* @StoWat2002a, @StoWat2002

* @DeEtAl2019: Machine learning extension


## Series $\bm{y}_t\in \mathbb{R}^m$

```{r series}
```

## Components $\bm{c}_t = \bm{\Phi}\bm{y}_t \in \mathbb{R}^p$

```{r components}
```

## FLAP

$$
\bm{z}_t = \begin{bmatrix} \bm{y}_t\\ \bm{c}_t \end{bmatrix}
\qquad \tilde{\bm{z}}_{t+h} = \bm{M} \hat{\bm{z}}_{t+h}
$$

\begin{block}{}

$$
\tilde{\bm{y}}_{t+h} = \bm{J}\tilde{\bm{z}}_{t+h} = \bm{J}\bm{M}\hat{\bm{z}}_{t+h}
$$
\end{block}

$$
\begin{aligned}
\bm{M} &= \bm{I}_{m+p} - \bm{W}_h\bm{C}'(\bm{C}\bm{W}_h\bm{C}')^{-1}\bm{C}\\
\bm{J} &= \bm{J}_{m,p} = \big[\bm{I}_m ~~~ \bm{O}_{m\times p}\big]\\
\bm{C} &= \big[- \bm{\Phi} ~~~ \bm{I}_{p}\big]\\
\bm{W}_h &= \Var(\bm{z}_{t+h} - \hat{\bm{z}}_{t+h})
\end{aligned}
$$


## Forecasts and FLAP of series 

```{r series-fc}
```



## Nonnegative variance reduction

The variance reduction is __positive semi-definite__:
$$
\begin{aligned}
\Var(\bm{y}_{t+h} - \hat{\bm{y}}_{t+h}) &-\Var(\bm{y}_{t+h} - \tilde{\bm{y}}_{t+h})\\ 
&= \bm{J}\bm{W}_h\bm{C}'(\bm{C}\bm{W}_h\bm{C}')^{-1}\bm{C}\bm{W}_h\bm{J}'
\end{aligned}
$$


## Projection matrix

\begin{alertblock}{Projection matrix}
The matrix $\bm{M}$ is a projection onto the space where the constraint $\bm{C}\bm{z}_t=\bm{0}$ is satisfied.
\end{alertblock}

### Properties

1. The projected forecast $\tilde{\bm{z}}_{t+h}$ satisfies the constraint $\bm{C}\tilde{\bm{z}}_{t+h}=\bm{0}$.
1. For $\bm{z}_{t+h}$ that already satisfies the constraint, the projection does not change its value: $\bm{M}\bm{z}_{t+h} = \bm{z}_{t+h}$ 
1. If the base forecasts are unbiased, then the FLAP forecasts are also unbiased.

## Geometry of FLAP

```{r geometry}
#| cache: false
knitr::read_chunk("flap-geometry.R")
```

```{r geometry-load}
#| cache: false
```


```{r ortho-1}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```

## Geometry of FLAP
```{r ortho-2}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```

## Geometry of FLAP
```{r ortho-3}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```

## Geometry of FLAP
```{r ortho-4}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```

## Geometry of FLAP
```{r ortho-5}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```
## Geometry of FLAP
```{r obliq-1}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```
## Geometry of FLAP
```{r obliq-2}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```
## Geometry of FLAP
```{r obliq-3}
#| cache: false
#| output: false
```
```{r geom-out}
#| cache: false
#| output: asis
```






## Example $\bm{W}_h = \bm{I}_{m+p}$

$$
\begin{aligned}
\Var(\bm{y}_{t+h} - \hat{\bm{y}}_{t+h}) &-\Var(\bm{y}_{t+h} - \tilde{\bm{y}}_{t+h})\\ 
&= \bm{J}\bm{C}'(\bm{C}\bm{C}')^{-1}\bm{C}\bm{J}'\\
&= \bm{\Phi}'
(\bm{\Phi}\bm{\Phi}' + \bm{I})^{-1}
\bm{\Phi}
\end{aligned}
$$

Let $\bm{\Phi}$ consist of orthogonal unit vectors:
$$
\begin{aligned}
\bm{\Phi}\bm{\Phi}' &= \bm{I}_p\text{ when } p\le m\\
\bm{\Phi}'\bm{\Phi} &= \bm{I}_m\text{ when } p= m.
\end{aligned}
$$

$$
\begin{aligned}
\tr(\Var(\bm{y}_{t+h} - \hat{\bm{y}}_{t+h}) &-\Var(\bm{y}_{t+h} - \tilde{\bm{y}}_{t+h})) \\
&=\frac{1}{2}tr(\bm{\Phi}'\bm{\Phi})=\frac{1}{2}p
\end{aligned}
$$

## Positive condition

For the first component to have a guaranteed reduction of forecast error variance, the following condition must be satisfied:

$$
\bm{\phi}_1\bm{W}_{y,h}\neq\bm{w}_{c_1y,h},
$$

* $\bm{\phi}_1$ is the weight vector of the first component
* $\bm{W}_{y,h} = \Var(\bm{y}_{t+h} - \hat{\bm{y}}_{t+h})$ 
* $\bm{w}_{c_1y,h}$ is the forecast error covariance between the first component and the original series.


## Monotonicity

The forecast error variance reductions, i.e. the diagonal elements of
$$
\begin{aligned}
\Var(\bm{y}_{t+h} &- \hat{\bm{y}}_{t+h}) -\Var(\bm{y}_{t+h} - \tilde{\bm{y}}_{t+h}) \\&= \bm{J}\bm{W}_h\bm{C}'(\bm{C}\bm{W}_h\bm{C}')^{-1}\bm{C}\bm{W}_h\bm{J}'
\end{aligned}
$$
is non-decreasing as $p$ increases.

## Minimum variance of individual series

The projection is equivalent to the mapping
$$
\tilde{\bm{y}}_{t+h} = \bm{G}\hat{\bm{z}}_{t+h},
$$
where $\bm{G} = \big[\bm{g}_1 ~~ \bm{g}_2 ~~ \dots ~~ \bm{g}_m\big]' \in \mathbb{R}^{m\times (m+p)}$ is the solution to
$$
\underset{\bm{G}}{\arg\min}\ \bm{G}\bm{W}_h\bm{G}'
\qquad \text{s.t. } \bm{G}\bm{S} = \bm{I}
$$ 
or
$$
\underset{\bm{g}_i}{\arg\min}\ \bm{g}_i'\bm{W}_h\bm{g}_i
\qquad \text{s.t. } \bm{g}_i'\bm{s}_{j} = \bm{1}(i=j),
$$
where $\bm{S} = \begin{bmatrix}\bm{I}_m \\\bm{\Phi}\end{bmatrix} = \big[\bm{s}_1\cdots \bm{s}_m\big]$.

## Key results

1. The forecast error variance is __reduced__ with FLAP
1. The forecast error variance __monotonically__ decreases with increasing number of components
1. The forecast projection is __optimal__ to achieve minimum forecast error variance of each series

## In practice, we need to

$$
\tilde{\bm{y}}_{t+h} = \bm{J}\tilde{\bm{z}}_{t+h} = \bm{J}\bm{M}\hat{\bm{z}}_{t+h}
$$

\begin{block}{}

$$
\bm{M} = \bm{I}_{m+p} - \bm{W}_h\bm{C}'(\bm{C}\bm{W}_h\bm{C}')^{-1}\bm{C}
$$
\end{block}

$$
\begin{aligned}
\bm{W}_h &= \Var(\bm{z}_{t+h} - \hat{\bm{z}}_{t+h})\\
\bm{C} &= \big[- \bm{\Phi} ~~~ \bm{I}_{p}\big]\\
\end{aligned}
$$

* Estimate $\bm{W}_h$
* Construct $\bm{\Phi}$


## Estimation of $\bm{W}_h$

__Shrinking variance__ towards their median [@OpgStr2007] and __shrinking covariance__ towards zero [@SchStr2005].

The shrinkage estimator is

* Positive definite, and 
* Numerically stable.

In empirical applications, we assume
$$
\widehat{\bm{W}}_h^{shr} = \eta_h\widehat{\bm{W}}_1^{shr}.
$$

## Construction of $\bm{\Phi}$

### Principal component analysis (PCA)

Finding the weights matrix so that the resulting components \alert{\textbf{maximise variance}}

### Simulation

Generating values from a random distribution and normalising them to unit vectors

* Normal distribution
* Uniform distribution
* Orthonormal matrix [@pracma]


## Tourism (ETS)

```{r visnights}
```


## FRED-MD (DFM)

```{r fred-md}
```

## Simulation

* Data generating process (DGP): VAR($3$) with $m=70$ variables
* Sample size: $T=400$
* Number of repeated samples: $220$
* Base model: ARIMA and DFM

## Simulation

```{r simulation}
```
<!-- 
## Future research directions

* Investigate why PCA performs better than random weights
* Find other components that are better than PCA
* Find optimal components by minimising forecast error variance with respect to $\bm{\Phi}$
* Use forecast projection and forecast reconciliation together -->

## R Package `flap`

You can install the stable version from CRAN
``` r
## CRAN.R-project.org/package=flap
install.packages("flap")
``` 
or the development version from Github
```r
## github.com/FinYang/flap
# install.packages("remotes")
remotes::install_github("FinYang/flap")
```

## Working paper and contact

- [yangzhuoranyang.com/publication/flap/](https://yangzhuoranyang.com/publication/flap/)

```{r}
#| fig-align: center
#| out-width: 180px
knitr::include_graphics("qr-code.png")
```

- Email: [Fin.Yang@monash.edu](mailto:Fin.Yang@monash.edu)
- [yangzhuoranyang.com](https://yangzhuoranyang.com)

## References {.allowframebreaks}

::: {#refs}
:::
